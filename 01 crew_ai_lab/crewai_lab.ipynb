{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building Your First AI Crew with crewAI (The Modern Way)\n",
    "\n",
    "## 1. Introduction & Lab Goals\n",
    "\n",
    "Welcome to the next step in your AI agent journey! This notebook will guide you through using **crewAI**, a sophisticated framework designed to orchestrate multiple AI agents. We will be using the latest, most streamlined method for connecting to Large Language Models (LLMs).\n",
    "\n",
    "Our goal is to build a simple **Research Crew** multi-agent workflow that researches a topic and writes a report.\n",
    "\n",
    "The logic flow will look like this:\n",
    "\n",
    "<img src=\"img_1.png\" alt=\"description\" width=\"500\">"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Prerequisites\n",
    "\n",
    "* **Knowledge:** Basic understanding of Python programming.\n",
    "* **API Key and Datarobot Endpoint:** This lab is configured for **Datarobot LLM Gateway**. For external IDE use, you will need a datarobot API credentials, and Datarobot API endpoint. You can set these environment variables, as indicated below.\n",
    "* **Python Version:** These labs are intended to be run on `python 3.11` or `python 3.12.` Others may work, but are untested."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 1: Project Setup and Installation\n",
    "\n",
    "First, let's install the necessary libraries. All the required libraries are included in ../requirements.txt\n",
    "If you do not have uv installed, please unremark the first line."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#!pip install uv\n",
    "!uv pip install -r ../requirements.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First, we will connect to the Datarobot LLM Gateway and list the available LLMs.\n",
    "The code below will connect to ANY of the LLMs hosted in the Datarobot LLM Gateway. For direct connections to external or customer hosted LLMS, you'll need to populate accordingly."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datarobot as dr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "\n",
    "load_dotenv('../.env') #use only with local IDE\n",
    "\n",
    "import openai\n",
    "#grab dr client credentials from os environment variables\n",
    "#dr_client = dr.Client() #use in datarobot notebooks w/o credentials\n",
    "dr_client = dr.Client(endpoint=os.getenv('DATAROBOT_ENDPOINT'), token=os.getenv('DATAROBOT_API_TOKEN')) #use for external IDE w/ environment variable credentials.\n",
    "\n",
    "#set LLM Gateway\n",
    "DR_API_TOKEN = dr_client.token\n",
    "LLM_GATEWAY_BASE_URL = f\"{dr_client.endpoint}/genai/llmgw\"\n",
    "response = dr_client.get(url=\"genai/llmgw/catalog/\")\n",
    "catalog = response.json()[\"data\"]\n",
    "\n",
    "response = dr_client.get(url=\"genai/llmgw/catalog/\")\n",
    "data = response.json()[\"data\"]\n",
    "supported_llms = [llm_model[\"model\"] for llm_model in data]\n",
    "\n",
    "print(\"These are list of LLMs supported by the Datarobot LLM Gateway:\")\n",
    "pprint(supported_llms)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Next, we are going to choose a random entry from the list of LLMS that was returned:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=dr_client.token,\n",
    "    base_url=dr_client.endpoint + \"/genai/llmgw\"\n",
    ")\n",
    "\n",
    "# We are going to select a RANDOM model from the list above... feel free to hard code your preference!!!\n",
    "#model = random.choice(supported_llms)\n",
    "model = 'bedrock/mistral.mixtral-8x7b-instruct-v0:1'\n",
    "#model = 'bedrock/meta.llama3-70b-instruct-v1:0'\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "     messages= [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": f\"Who are you? {model}\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "pprint(model)\n",
    "pprint(response.choices[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#use this for troubleshooting endpoint and token issues\n",
    "print(dr_client.token)\n",
    "print(dr_client.endpoint + \"/genai/llmgw\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2: Create a Custom DuckDuckGo Search Tool\n",
    "\n",
    "Since the CrewAI DuckDuckGoSearchRunTool is not available in the current version, we'll create our own custom search tool using the `duckduckgo-search` library directly."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from crewai.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type\n",
    "from ddgs import DDGS\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    \"\"\"Input schema for DuckDuckGo search tool.\"\"\"\n",
    "    query: str = Field(..., description=\"The search query\")\n",
    "\n",
    "class DuckDuckGoSearchTool(BaseTool):\n",
    "    name: str = \"duckduckgo_search\"\n",
    "    description: str = \"Search the web using DuckDuckGo for current information\"\n",
    "    args_schema: Type[BaseModel] = SearchInput\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Execute the search and return formatted results.\"\"\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                # Try news search first\n",
    "                news_results = list(ddgs.news(query, max_results=5))\n",
    "\n",
    "                if news_results:\n",
    "                    formatted_results = []\n",
    "                    formatted_results.append(f\"Search Results for: {query}\")\n",
    "                    formatted_results.append(f\"Search performed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "                    formatted_results.append(\"\\n=== NEWS RESULTS ===\")\n",
    "\n",
    "                    for i, result in enumerate(news_results, 1):\n",
    "                        title = result.get('title', 'No title')\n",
    "                        body = result.get('body', '')\n",
    "                        url = result.get('url', '')\n",
    "                        date = result.get('date', 'Recent')\n",
    "\n",
    "                        formatted_results.append(f\"\\n{i}. {title}\")\n",
    "                        if body:\n",
    "                            # Truncate body to keep it manageable\n",
    "                            body_snippet = body[:300] + \"...\" if len(body) > 300 else body\n",
    "                            formatted_results.append(f\"   Summary: {body_snippet}\")\n",
    "                        formatted_results.append(f\"   Date: {date}\")\n",
    "                        formatted_results.append(f\"   Source: {url}\")\n",
    "\n",
    "                    return \"\\n\".join(formatted_results)\n",
    "\n",
    "                # If no news results, try regular web search\n",
    "                web_results = list(ddgs.text(query, max_results=5))\n",
    "\n",
    "                if web_results:\n",
    "                    formatted_results = []\n",
    "                    formatted_results.append(f\"Search Results for: {query}\")\n",
    "                    formatted_results.append(f\"Search performed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "                    formatted_results.append(\"\\n=== WEB RESULTS ===\")\n",
    "\n",
    "                    for i, result in enumerate(web_results, 1):\n",
    "                        title = result.get('title', 'No title')\n",
    "                        body = result.get('body', '')\n",
    "                        url = result.get('href', '')\n",
    "\n",
    "                        formatted_results.append(f\"\\n{i}. {title}\")\n",
    "                        if body:\n",
    "                            # Truncate body to keep it manageable\n",
    "                            body_snippet = body[:300] + \"...\" if len(body) > 300 else body\n",
    "                            formatted_results.append(f\"   Summary: {body_snippet}\")\n",
    "                        formatted_results.append(f\"   Source: {url}\")\n",
    "\n",
    "                    return \"\\n\".join(formatted_results)\n",
    "\n",
    "                else:\n",
    "                    return f\"No search results found for: {query}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Search error for '{query}': {str(e)}\"\n",
    "\n",
    "# Create the search tool instance\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "print(\"âœ… Custom DuckDuckGo search tool created successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 3: Define the Crew\n",
    "\n",
    "Now we define the agents and tasks. This is the heart of crewAI - creating specialized agents that can work together to accomplish complex goals.\n",
    "\n",
    "**ðŸ“š For sample configuration, refer to the [CrewAI Research Lab Setup Guide](../CrewAI_ResearchLab_Setup.md)**\n",
    "\n",
    "#### Key Components You'll Create:\n",
    "\n",
    "1. **LLM Configuration** - Set up your connection to the DataRobot LLM Gateway\n",
    "2. **Agents** - Define specialized AI workers with distinct roles and capabilities\n",
    "3. **Tasks** - Create specific assignments for each agent to complete\n",
    "4. **Crew** - Organize agents and tasks into a collaborative workflow\n",
    "\n",
    "#### Understanding the Architecture:\n",
    "\n",
    "- **Agent**: A specialized AI worker with a specific role (e.g., Researcher, Writer)\n",
    "- **Task**: A specific job assigned to an agent with clear expectations\n",
    "- **Tool**: Capabilities you give to agents (like our search tool)\n",
    "- **Crew**: The orchestrator that manages agents and tasks in sequence\n",
    "\n",
    "#### Important Configuration Notes:\n",
    "\n",
    "- `verbose=True/False`: Controls output verbosity (set to False for DataRobot compatibility)\n",
    "- `allow_delegation=True/False`: Whether agents can delegate tasks to other agents\n",
    "- `custom_llm_provider=\"openai\"`: Required for DataRobot LLM Gateway compatibility\n",
    "- `process=Process.sequential`: Tasks execute one after another (vs. parallel)\n",
    "\n",
    "**Complete and Run the code below to create your research crew:**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "\n",
    "# --- LLM Configuration for DataRobot Gateway ---\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=model,\n",
    "    api_key=dr_client.token,\n",
    "    base_url=dr_client.endpoint + \"/genai/llmgw\",\n",
    "    custom_llm_provider=\"openai\"  # Force liteLLM to treat this as OpenAI\n",
    ")\n",
    "\n",
    "# --- Agent & Task Definitions ---\n",
    "# Define the Researcher Agent\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='',\n",
    "  backstory=''' ''',\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[search_tool],  # Using our custom search tool\n",
    "  llm=llm  # Pass the LLM object, not a string\n",
    ")\n",
    "\n",
    "# Define the Writer Agent\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='',\n",
    "  backstory=''' ''',\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  llm=llm  # Pass the LLM object, not a string\n",
    ")\n",
    "\n",
    "# Create the Research Task\n",
    "research_task = Task(\n",
    "  description=''' ''',\n",
    "  expected_output=' ',\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "# Create the Writing Task\n",
    "writing_task = Task(\n",
    "  description=''' ''',\n",
    "  expected_output=' ',\n",
    "  agent=writer\n",
    ")\n",
    "\n",
    "# --- Crew Definition ---\n",
    "crew = Crew(\n",
    "  agents=[],\n",
    "  tasks=[],\n",
    "  process=Process.sequential,\n",
    "  verbose=True  # Set to False for DataRobot notebook compatibility\n",
    ")\n",
    "\n",
    "print(\"âœ… Crew and tasks are defined and ready to run.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 4: Run Your AI Crew\n",
    "\n",
    "With everything set up, let's kick off the crew's work. This will start the sequential process, and you will see the agents' thoughts and actions in the output below."
   ]
  },
  {
   "cell_type": "code",
   "source": "result = crew.kickoff()\n\nprint(\"\\n\\n########################\")\nprint(\"## Here is your crew's result:\")\nprint(\"########################\\n\")\nprint(result)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Testing the Search Tool\n",
    "\n",
    "Let's test our custom search tool to make sure it works correctly:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test the search tool directly\n",
    "test_query = \"latest AI developments coming in 2026\"\n",
    "test_result = search_tool._run(test_query)\n",
    "\n",
    "print(\"=== SEARCH TOOL TEST ===\")\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"\\nResults:\")\n",
    "print(test_result[:5000] + \"...\" if len(test_result) > 5000 else test_result)\n",
    "print(\"\\n=== TEST COMPLETED ===\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
